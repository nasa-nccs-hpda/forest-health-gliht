# Forest Health using G-LIHT

Deep learning algorithms to map damaged trees in forests.

## Data Locations

This repository includes the training, test, and validation data generated by
Anika in an old iteration of this project. The data is listed below:

- `data/*.png`: images are the original camera and labels data generated by Anika
- `data/*.json`: COCO-formatted dataset for the original megratron model

## Original Modeling Methodology

The original methodology was based on the MaskRCNN model. We used the detectron2 framework to train
a MaskRCNN model using transfer learning. The problem would receive camera images as input, and boundary
segmentations of dead trees. This therefore allowed us to perform instance segmentation of trees to both find
them, and then also specify their health status (dead or not dead).

We focused the training data only in dead trees, thus our outputs would only find trees that were dead. The
training dataset was relatively small, but leveraging transfer learning allowed us to be able to find dead
trees without significant labeling efforts.

Since Anika left, the project was stopped. But this are the things I would have liked to fix/work on:
- New/updated model (YOLO for example)
- Labels that include all types of trees, but then are sublabeled as dead or not dead
- Automated pipeline to process full scenes

## New Example Modeling Methodology

A possible improvement on the current setup is to use existing foundation models with
newer architectures such as YOLO and state-of-the-art object detection. The MaskRCNN
notebook under the `notebooks` directory has details on running the previous workflow
using a sample dataset created by Anika.

## Environment Setup

The dependencies are installed from the notebooks themselves.

## References

Some useful references to learn more and be able to use other tools are listed below:

- [Awesome repository and notebook examples to use foundation model backends ( I am pretty sure this can give you state of the art for the camera photos)](https://github.com/autodistill/autodistill)
- [Easy implementation of yolov8](https://github.com/roboflow/supervision)
- [Good number of notebooks with introductory materials](https://github.com/roboflow/notebooks)
- [Segmentation of lidar using SAM model](https://github.com/Yarroudh/segment-lidar)
- [Accelerate labeling using SAM as the backend](https://github.com/opengeos/segment-geospatial)
- [Additional RGB highres pretrained weights](https://torchgeo.readthedocs.io/en/stable/api/models.html)
